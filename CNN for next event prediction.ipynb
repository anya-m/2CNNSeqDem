{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " CNN for next event prediction                 \n",
      "============================================================\n",
      "Training & evaluation 1 : accuracy = 0.942 time = 9.57\n",
      "Training & evaluation 2 : accuracy = 0.921 time = 7.93\n",
      "Training & evaluation 3 : accuracy = 0.929 time = 7.91\n",
      "Training & evaluation 4 : accuracy = 0.931 time = 7.97\n",
      "Training & evaluation 5 : accuracy = 0.923 time = 8.04\n",
      "Training & evaluation 6 : accuracy = 0.926 time = 7.93\n",
      "Training & evaluation 7 : accuracy = 0.931 time = 7.93\n",
      "Training & evaluation 8 : accuracy = 0.934 time = 7.95\n",
      "Training & evaluation 9 : accuracy = 0.940 time = 7.97\n",
      "Training & evaluation 10 : accuracy = 0.930 time = 8.17\n",
      "\n",
      "Model training & evaluation time (mean): 8.17\n",
      "Accuracy (mean): 0.931 , Variance: 0.000041 , Standard deviation: 0.006442\n",
      "==========================================================================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.backend import backend\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import * \n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#print(gpus)\n",
    "\n",
    "print (\"============================================================\")\n",
    "print (\" CNN for next event prediction                              \")\n",
    "print (\"============================================================\")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "acc_list = []\n",
    "\n",
    "df = pd.read_excel(\"table.xlsx\")\n",
    "df.dropna(inplace = True) \n",
    "\n",
    "n = 10\n",
    "for ii in range(1, n+1):\n",
    "    \n",
    "    time_02 = time.time()\n",
    "\n",
    "    df = shuffle(df) \n",
    "\n",
    "    size = df.shape[0]\n",
    "    t = int(size * 0.8)         # train part size\n",
    "\n",
    "    x = df.values[:size, 0:7]\n",
    "    y = np.empty(size, dtype=str)\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        y[i] = x[i, 0][-1]\n",
    "        x[i, 0] = x[i, 0][:-1]\n",
    "\n",
    "    X = np.empty((x.shape[0], x.shape[1]), dtype='int32')\n",
    "\n",
    "    for d in range(x.shape[1]):        \n",
    "        xs = list(set(x[:, d]))\n",
    "\n",
    "        xd = {xs[i]: i for i in range(len(xs))}\n",
    "        for l in range(x.shape[0]):\n",
    "            X[l][d] = xd[x[l][d]]\n",
    "\n",
    "\n",
    "    XF_train = X[0:t, 1:]           # train features \n",
    "    XF_test  = X[t:size, 1:]        # test features\n",
    "\n",
    "    yn = np.empty((size), dtype='int32')\n",
    "\n",
    "    ys = list(set(y[:]))\n",
    "    yd = {ys[i]: i for i in range(len(ys))}\n",
    "    for l in range(len(yn)):\n",
    "        yn[l] = yd[y[l]]\n",
    "\n",
    "    y_train = yn[0:t]\n",
    "    y_test  = yn[t:size]\n",
    "\n",
    "    # all unique characters to the set\n",
    "    events = set()\n",
    "    for seq in x[:, 0]:\n",
    "        for event in seq:\n",
    "            events.add(event)\n",
    "\n",
    "    events = list(events)\n",
    "    event_to_id = {t:i+1 for i,t in enumerate(events)}\n",
    "\n",
    "    max_seq_len = 8\n",
    "    seq_events_numbered = np.zeros((x.shape[0], max_seq_len), dtype='int32')\n",
    "\n",
    "    for i in range(seq_events_numbered.shape[0]):\n",
    "        for k in range(len(x[i][0])):\n",
    "            seq_events_numbered[i][k] = event_to_id[x[i][0][k]]\n",
    "\n",
    "    S_train = seq_events_numbered[0:t, :]       # train sequences\n",
    "    S_test  = seq_events_numbered[t:size, :]    # test  sequences\n",
    "\n",
    "    \n",
    "    def define_model(seq_length, vocab_size, features_n): # for sequences: length=8, vocab_size=9 (include ' ') \n",
    "\n",
    "        input_seq = Input(shape=(seq_length,)) \n",
    "        \n",
    "        # sequences\n",
    "        seq = Embedding(vocab_size, 100)(input_seq)\n",
    "        seq = Conv1D(128, kernel_size=8, activation='relu')(seq)\n",
    "        seq = Dropout(0.05)(seq)\n",
    "        seq = Flatten()(seq)\n",
    "        \n",
    "        # features\n",
    "        input_features = Input(shape=(features_n, ))\n",
    "        features = Dense(128, activation='relu')(input_features)\n",
    "        features = Dropout(0.05)(features)\n",
    "        features = Flatten()(features)\n",
    "\n",
    "        # merged sequences and features\n",
    "        merged = concatenate([seq, features]) # merged sequences and features\n",
    "        merged = Dense(128, activation='relu')(merged)\n",
    "        merged = Dropout(0.05)(merged)\n",
    "        merged = Dense(32, activation='relu')(merged)\n",
    "        \n",
    "        outputs = Dense(8, activation='softmax')(merged)\n",
    "        model = Model(inputs=[input_seq, input_features], outputs=outputs)\n",
    "\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', \n",
    "                      metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    # define model\n",
    "    model = define_model(8, 9, 6)\n",
    "\n",
    "    # fit model\n",
    "    model.fit([S_train, XF_train], y_train, epochs=70, batch_size=100, verbose=0)\n",
    "\n",
    "    loss, acc = model.evaluate([S_test, XF_test], y_test, verbose=0)\n",
    "    acc_list.append(acc)\n",
    "    \n",
    "    print(\"Training & evaluation\", ii, \": accuracy = %0.3f\" % acc, \"time = %0.2f\" % (time.time() - time_02))\n",
    "\n",
    "time_03 = time.time()\n",
    "\n",
    "print (\"\\nModel training & evaluation time (mean): %0.2f\" % ((time_03 - start_time)/n))   \n",
    "print (\"Accuracy (mean): %.3f\" % np.mean((acc_list)), \", Variance: %.6f\" % (np.var(acc_list)), \n",
    "       \", Standard deviation: %.6f\" % (np.std(acc_list)))\n",
    "print (\"==========================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
