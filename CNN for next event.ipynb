{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " RNN for demographic sequences and features.  Anna Muratova \n",
      "============================================================\n",
      "Input data shape = (6626, 7)\n",
      "Number of unique sequences = 1069 \n",
      "\n",
      "Train features  data shape = (5300, 6) (5300,)\n",
      "Test  features  data shape = (1326, 6) (1326,)\n",
      "Train sequences data shape = (5300, 8) (5300,)\n",
      "Test  sequences data shape = (1326, 8) (1326,)\n",
      "\n",
      "Data preprocessing time, sec =  0.40\n",
      "============================================================\n",
      "Keras backend = tensorflow\n",
      "\n",
      "CNN classification by sequences and features\n",
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_61 (InputLayer)           [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_30 (Embedding)        (None, 8, 40)        360         input_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_62 (InputLayer)           [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1, 100)       32100       embedding_30[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_120 (Dense)               (None, 100)          700         input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 1, 100)       0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 100)          0           dense_120[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_60 (Flatten)            (None, 100)          0           dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_61 (Flatten)            (None, 100)          0           dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 200)          0           flatten_60[0][0]                 \n",
      "                                                                 flatten_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_121 (Dense)               (None, 200)          40200       concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 200)          0           dense_121[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_122 (Dense)               (None, 32)           6432        dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_123 (Dense)               (None, 8)            264         dense_122[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 80,056\n",
      "Trainable params: 80,056\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 5300 samples\n",
      "Epoch 1/100\n",
      "5300/5300 [==============================] - 1s 125us/sample - loss: 1.3977 - sparse_categorical_accuracy: 0.5208\n",
      "Epoch 2/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.5782 - sparse_categorical_accuracy: 0.8204\n",
      "Epoch 3/100\n",
      "5300/5300 [==============================] - 0s 42us/sample - loss: 0.3797 - sparse_categorical_accuracy: 0.8864\n",
      "Epoch 4/100\n",
      "5300/5300 [==============================] - 0s 43us/sample - loss: 0.3099 - sparse_categorical_accuracy: 0.9042\n",
      "Epoch 5/100\n",
      "5300/5300 [==============================] - 0s 42us/sample - loss: 0.2625 - sparse_categorical_accuracy: 0.9126\n",
      "Epoch 6/100\n",
      "5300/5300 [==============================] - 0s 45us/sample - loss: 0.2418 - sparse_categorical_accuracy: 0.9166\n",
      "Epoch 7/100\n",
      "5300/5300 [==============================] - 0s 50us/sample - loss: 0.2254 - sparse_categorical_accuracy: 0.9238\n",
      "Epoch 8/100\n",
      "5300/5300 [==============================] - 0s 61us/sample - loss: 0.2178 - sparse_categorical_accuracy: 0.9230\n",
      "Epoch 9/100\n",
      "5300/5300 [==============================] - 0s 47us/sample - loss: 0.2194 - sparse_categorical_accuracy: 0.9236\n",
      "Epoch 10/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.2021 - sparse_categorical_accuracy: 0.9270\n",
      "Epoch 11/100\n",
      "5300/5300 [==============================] - 0s 42us/sample - loss: 0.1910 - sparse_categorical_accuracy: 0.9321\n",
      "Epoch 12/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.1892 - sparse_categorical_accuracy: 0.9334\n",
      "Epoch 13/100\n",
      "5300/5300 [==============================] - 0s 43us/sample - loss: 0.1857 - sparse_categorical_accuracy: 0.9368\n",
      "Epoch 14/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.1786 - sparse_categorical_accuracy: 0.9370\n",
      "Epoch 15/100\n",
      "5300/5300 [==============================] - 0s 42us/sample - loss: 0.1735 - sparse_categorical_accuracy: 0.9343\n",
      "Epoch 16/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.1675 - sparse_categorical_accuracy: 0.9406\n",
      "Epoch 17/100\n",
      "5300/5300 [==============================] - 0s 43us/sample - loss: 0.1556 - sparse_categorical_accuracy: 0.9436\n",
      "Epoch 18/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.1591 - sparse_categorical_accuracy: 0.9442\n",
      "Epoch 19/100\n",
      "5300/5300 [==============================] - 0s 42us/sample - loss: 0.1585 - sparse_categorical_accuracy: 0.9415\n",
      "Epoch 20/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.1534 - sparse_categorical_accuracy: 0.9447\n",
      "Epoch 21/100\n",
      "5300/5300 [==============================] - 0s 39us/sample - loss: 0.1478 - sparse_categorical_accuracy: 0.9475\n",
      "Epoch 22/100\n",
      "5300/5300 [==============================] - 0s 39us/sample - loss: 0.1515 - sparse_categorical_accuracy: 0.9464\n",
      "Epoch 23/100\n",
      "5300/5300 [==============================] - 0s 43us/sample - loss: 0.1405 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 24/100\n",
      "5300/5300 [==============================] - 0s 40us/sample - loss: 0.1350 - sparse_categorical_accuracy: 0.9523\n",
      "Epoch 25/100\n",
      "5300/5300 [==============================] - 0s 42us/sample - loss: 0.1340 - sparse_categorical_accuracy: 0.9487\n",
      "Epoch 26/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.1257 - sparse_categorical_accuracy: 0.9538\n",
      "Epoch 27/100\n",
      "5300/5300 [==============================] - 0s 43us/sample - loss: 0.1325 - sparse_categorical_accuracy: 0.9496\n",
      "Epoch 28/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.1253 - sparse_categorical_accuracy: 0.9566\n",
      "Epoch 29/100\n",
      "5300/5300 [==============================] - 0s 38us/sample - loss: 0.1242 - sparse_categorical_accuracy: 0.9545\n",
      "Epoch 30/100\n",
      "5300/5300 [==============================] - 0s 38us/sample - loss: 0.1188 - sparse_categorical_accuracy: 0.9564\n",
      "Epoch 31/100\n",
      "5300/5300 [==============================] - 0s 47us/sample - loss: 0.1149 - sparse_categorical_accuracy: 0.9585\n",
      "Epoch 32/100\n",
      "5300/5300 [==============================] - 0s 42us/sample - loss: 0.1078 - sparse_categorical_accuracy: 0.9604\n",
      "Epoch 33/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.1093 - sparse_categorical_accuracy: 0.9592\n",
      "Epoch 34/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.1080 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 35/100\n",
      "5300/5300 [==============================] - 0s 45us/sample - loss: 0.1059 - sparse_categorical_accuracy: 0.9608\n",
      "Epoch 36/100\n",
      "5300/5300 [==============================] - 0s 38us/sample - loss: 0.1019 - sparse_categorical_accuracy: 0.9623\n",
      "Epoch 37/100\n",
      "5300/5300 [==============================] - 0s 45us/sample - loss: 0.0986 - sparse_categorical_accuracy: 0.9643\n",
      "Epoch 38/100\n",
      "5300/5300 [==============================] - 0s 44us/sample - loss: 0.0896 - sparse_categorical_accuracy: 0.9674\n",
      "Epoch 39/100\n",
      "5300/5300 [==============================] - 0s 40us/sample - loss: 0.0897 - sparse_categorical_accuracy: 0.9674\n",
      "Epoch 40/100\n",
      "5300/5300 [==============================] - 0s 44us/sample - loss: 0.0914 - sparse_categorical_accuracy: 0.9664\n",
      "Epoch 41/100\n",
      "5300/5300 [==============================] - 0s 43us/sample - loss: 0.0865 - sparse_categorical_accuracy: 0.9672\n",
      "Epoch 42/100\n",
      "5300/5300 [==============================] - 0s 40us/sample - loss: 0.0891 - sparse_categorical_accuracy: 0.9683\n",
      "Epoch 43/100\n",
      "5300/5300 [==============================] - 0s 42us/sample - loss: 0.0883 - sparse_categorical_accuracy: 0.9670\n",
      "Epoch 44/100\n",
      "5300/5300 [==============================] - 0s 40us/sample - loss: 0.0827 - sparse_categorical_accuracy: 0.9692\n",
      "Epoch 45/100\n",
      "5300/5300 [==============================] - 0s 39us/sample - loss: 0.0764 - sparse_categorical_accuracy: 0.9711\n",
      "Epoch 46/100\n",
      "5300/5300 [==============================] - 0s 40us/sample - loss: 0.0833 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 47/100\n",
      "5300/5300 [==============================] - 0s 39us/sample - loss: 0.0761 - sparse_categorical_accuracy: 0.9728\n",
      "Epoch 48/100\n",
      "5300/5300 [==============================] - 0s 39us/sample - loss: 0.0744 - sparse_categorical_accuracy: 0.9732\n",
      "Epoch 49/100\n",
      "5300/5300 [==============================] - 0s 44us/sample - loss: 0.0768 - sparse_categorical_accuracy: 0.9725\n",
      "Epoch 50/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.0738 - sparse_categorical_accuracy: 0.9723\n",
      "Epoch 51/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.0756 - sparse_categorical_accuracy: 0.9723\n",
      "Epoch 52/100\n",
      "5300/5300 [==============================] - 0s 40us/sample - loss: 0.0721 - sparse_categorical_accuracy: 0.9721\n",
      "Epoch 53/100\n",
      "5300/5300 [==============================] - 0s 42us/sample - loss: 0.0701 - sparse_categorical_accuracy: 0.9736\n",
      "Epoch 54/100\n",
      "5300/5300 [==============================] - 0s 46us/sample - loss: 0.0621 - sparse_categorical_accuracy: 0.9772\n",
      "Epoch 55/100\n",
      "5300/5300 [==============================] - 0s 40us/sample - loss: 0.0648 - sparse_categorical_accuracy: 0.9758\n",
      "Epoch 56/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.0598 - sparse_categorical_accuracy: 0.9791\n",
      "Epoch 57/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.0633 - sparse_categorical_accuracy: 0.9753\n",
      "Epoch 58/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.0746 - sparse_categorical_accuracy: 0.9721\n",
      "Epoch 59/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.0681 - sparse_categorical_accuracy: 0.9751\n",
      "Epoch 60/100\n",
      "5300/5300 [==============================] - 0s 44us/sample - loss: 0.0659 - sparse_categorical_accuracy: 0.9742\n",
      "Epoch 61/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.0533 - sparse_categorical_accuracy: 0.9809\n",
      "Epoch 62/100\n",
      "5300/5300 [==============================] - 0s 43us/sample - loss: 0.0614 - sparse_categorical_accuracy: 0.9774\n",
      "Epoch 63/100\n",
      "5300/5300 [==============================] - 0s 44us/sample - loss: 0.0615 - sparse_categorical_accuracy: 0.9772\n",
      "Epoch 64/100\n",
      "5300/5300 [==============================] - 0s 44us/sample - loss: 0.0597 - sparse_categorical_accuracy: 0.9787\n",
      "Epoch 65/100\n",
      "5300/5300 [==============================] - 0s 39us/sample - loss: 0.0603 - sparse_categorical_accuracy: 0.9787\n",
      "Epoch 66/100\n",
      "5300/5300 [==============================] - 0s 43us/sample - loss: 0.0554 - sparse_categorical_accuracy: 0.9789\n",
      "Epoch 67/100\n",
      "5300/5300 [==============================] - 0s 42us/sample - loss: 0.0515 - sparse_categorical_accuracy: 0.9819\n",
      "Epoch 68/100\n",
      "5300/5300 [==============================] - 0s 37us/sample - loss: 0.0549 - sparse_categorical_accuracy: 0.9785\n",
      "Epoch 69/100\n",
      "5300/5300 [==============================] - 0s 39us/sample - loss: 0.0564 - sparse_categorical_accuracy: 0.9789\n",
      "Epoch 70/100\n",
      "5300/5300 [==============================] - 0s 38us/sample - loss: 0.0555 - sparse_categorical_accuracy: 0.9785\n",
      "Epoch 71/100\n",
      "5300/5300 [==============================] - 0s 37us/sample - loss: 0.0603 - sparse_categorical_accuracy: 0.9781\n",
      "Epoch 72/100\n",
      "5300/5300 [==============================] - 0s 40us/sample - loss: 0.0522 - sparse_categorical_accuracy: 0.9817\n",
      "Epoch 73/100\n",
      "5300/5300 [==============================] - 0s 42us/sample - loss: 0.0506 - sparse_categorical_accuracy: 0.9796\n",
      "Epoch 74/100\n",
      "5300/5300 [==============================] - 0s 43us/sample - loss: 0.0488 - sparse_categorical_accuracy: 0.9809\n",
      "Epoch 75/100\n",
      "5300/5300 [==============================] - 0s 40us/sample - loss: 0.0542 - sparse_categorical_accuracy: 0.9796\n",
      "Epoch 76/100\n",
      "5300/5300 [==============================] - 0s 43us/sample - loss: 0.0473 - sparse_categorical_accuracy: 0.9811\n",
      "Epoch 77/100\n",
      "5300/5300 [==============================] - 0s 42us/sample - loss: 0.0494 - sparse_categorical_accuracy: 0.9798\n",
      "Epoch 78/100\n",
      "5300/5300 [==============================] - 0s 44us/sample - loss: 0.0478 - sparse_categorical_accuracy: 0.9808\n",
      "Epoch 79/100\n",
      "5300/5300 [==============================] - 0s 39us/sample - loss: 0.0482 - sparse_categorical_accuracy: 0.9804\n",
      "Epoch 80/100\n",
      "5300/5300 [==============================] - 0s 37us/sample - loss: 0.0484 - sparse_categorical_accuracy: 0.9811\n",
      "Epoch 81/100\n",
      "5300/5300 [==============================] - 0s 39us/sample - loss: 0.0507 - sparse_categorical_accuracy: 0.9777\n",
      "Epoch 82/100\n",
      "5300/5300 [==============================] - 0s 43us/sample - loss: 0.0486 - sparse_categorical_accuracy: 0.9819\n",
      "Epoch 83/100\n",
      "5300/5300 [==============================] - 0s 45us/sample - loss: 0.0535 - sparse_categorical_accuracy: 0.9781\n",
      "Epoch 84/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.0500 - sparse_categorical_accuracy: 0.9800\n",
      "Epoch 85/100\n",
      "5300/5300 [==============================] - 0s 40us/sample - loss: 0.0499 - sparse_categorical_accuracy: 0.9821\n",
      "Epoch 86/100\n",
      "5300/5300 [==============================] - 0s 42us/sample - loss: 0.0495 - sparse_categorical_accuracy: 0.9808\n",
      "Epoch 87/100\n",
      "5300/5300 [==============================] - 0s 42us/sample - loss: 0.0474 - sparse_categorical_accuracy: 0.9817\n",
      "Epoch 88/100\n",
      "5300/5300 [==============================] - 0s 39us/sample - loss: 0.0576 - sparse_categorical_accuracy: 0.9785\n",
      "Epoch 89/100\n",
      "5300/5300 [==============================] - 0s 42us/sample - loss: 0.0492 - sparse_categorical_accuracy: 0.9806\n",
      "Epoch 90/100\n",
      "5300/5300 [==============================] - 0s 39us/sample - loss: 0.0551 - sparse_categorical_accuracy: 0.9794\n",
      "Epoch 91/100\n",
      "5300/5300 [==============================] - 0s 38us/sample - loss: 0.0436 - sparse_categorical_accuracy: 0.9834\n",
      "Epoch 92/100\n",
      "5300/5300 [==============================] - 0s 40us/sample - loss: 0.0479 - sparse_categorical_accuracy: 0.9806\n",
      "Epoch 93/100\n",
      "5300/5300 [==============================] - 0s 40us/sample - loss: 0.0459 - sparse_categorical_accuracy: 0.9826\n",
      "Epoch 94/100\n",
      "5300/5300 [==============================] - 0s 40us/sample - loss: 0.0439 - sparse_categorical_accuracy: 0.9821\n",
      "Epoch 95/100\n",
      "5300/5300 [==============================] - 0s 39us/sample - loss: 0.0447 - sparse_categorical_accuracy: 0.9825\n",
      "Epoch 96/100\n",
      "5300/5300 [==============================] - 0s 39us/sample - loss: 0.0444 - sparse_categorical_accuracy: 0.9802\n",
      "Epoch 97/100\n",
      "5300/5300 [==============================] - 0s 39us/sample - loss: 0.0448 - sparse_categorical_accuracy: 0.9832\n",
      "Epoch 98/100\n",
      "5300/5300 [==============================] - 0s 41us/sample - loss: 0.0394 - sparse_categorical_accuracy: 0.9838\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5300/5300 [==============================] - 0s 43us/sample - loss: 0.0438 - sparse_categorical_accuracy: 0.9802\n",
      "Epoch 100/100\n",
      "5300/5300 [==============================] - 0s 44us/sample - loss: 0.0433 - sparse_categorical_accuracy: 0.9821\n",
      "Test Accuracy: 0.937406\n",
      "\tModel fitting time .... 22.76\n",
      "\tPrediction time ....... 0.12\n",
      "\tTotal time ............ 22.88\n",
      "Accuracy: 0.937\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.backend import backend\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import * \n",
    "\n",
    "\n",
    "print (\"============================================================\")\n",
    "print (\" CNN for demographic sequences and features.  Anna Muratova \")\n",
    "print (\"============================================================\")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df = pd.read_excel(\"table.xlsx\")\n",
    "\n",
    "df.dropna(inplace = True)   # remove empty (NaN) lines\n",
    "df = shuffle(df, random_state=7)\n",
    "\n",
    "print (\"Input data shape =\", df.shape)\n",
    "size = df.shape[0]\n",
    "t = int(size * 0.8)         # train part size\n",
    "\n",
    "x = df.values[:size, 0:7]\n",
    "y = np.empty(size, dtype=str)\n",
    "del df\n",
    "\n",
    "for i in range(x.shape[0]):\n",
    "    y[i] = x[i, 0][-1]\n",
    "    x[i, 0] = x[i, 0][:-1]\n",
    "\n",
    "\n",
    "X = np.empty((x.shape[0], x.shape[1]), dtype='int32')\n",
    "\n",
    "for d in range(x.shape[1]):        \n",
    "    xs = list(set(x[:, d]))\n",
    "    if d == 0:\n",
    "        print (\"Number of unique sequences =\", len(xs), \"\\n\")\n",
    "    xd = {xs[i]: i for i in range(len(xs))}\n",
    "    for l in range(x.shape[0]):\n",
    "        X[l][d] = xd[x[l][d]]\n",
    "\n",
    "\n",
    "XF_train = X[0:t, 1:]           # features only\n",
    "XF_test  = X[t:size, 1:]\n",
    "#print (XF_train[0:5])\n",
    "\n",
    "yn = np.empty((size), dtype='int32')\n",
    "\n",
    "ys = list(set(y[:]))\n",
    "yd = {ys[i]: i for i in range(len(ys))}\n",
    "for l in range(len(yn)):\n",
    "    yn[l] = yd[y[l]]\n",
    "\n",
    "y_train = yn[0:t]\n",
    "y_test  = yn[t:size]\n",
    "\n",
    "# all unique characters to the set\n",
    "events = set()\n",
    "for seq in x[:, 0]:\n",
    "    for event in seq:\n",
    "        events.add(event)\n",
    "\n",
    "events = list(events)\n",
    "\n",
    "event_to_id = {t:i+1 for i,t in enumerate(events)}\n",
    "\n",
    "#print (event_to_id)\n",
    "\n",
    "max_seq_len = 8\n",
    "seq_events_numbered = np.zeros((x.shape[0], max_seq_len), dtype='int32')\n",
    "\n",
    "for i in range(seq_events_numbered.shape[0]):\n",
    "    for k in range(len(x[i][0])):\n",
    "        seq_events_numbered[i][k] = event_to_id[x[i][0][k]]\n",
    "\n",
    "S_train = seq_events_numbered[0:t, :]       # train sequences\n",
    "S_test  = seq_events_numbered[t:size, :]    # test  sequences\n",
    "\n",
    "\n",
    "print (\"Train features  data shape =\", XF_train.shape, y_train.shape)\n",
    "print (\"Test  features  data shape =\", XF_test.shape,  y_test.shape)\n",
    "print (\"Train sequences data shape =\", S_train.shape, y_train.shape)\n",
    "print (\"Test  sequences data shape =\", S_test.shape,  y_test.shape)\n",
    "print (\"\\nData preprocessing time, sec =  %0.2f\" % (time.time() - start_time))\n",
    "\n",
    "print (\"============================================================\")\n",
    "\n",
    "print (\"Keras backend =\", backend())\n",
    "\n",
    "def define_model(seq_length, vocab_size, features_n): # for sequences: length = 8, vocab_size = 9 (including ' ') \n",
    "\tinput_seq = Input(shape=(seq_length,)) \n",
    "\t# sequences\n",
    "\tembedding_s = Embedding(vocab_size, 40)(input_seq)\n",
    "\tconv_s = Conv1D(filters=100, kernel_size=8, activation='relu')(embedding_s)\n",
    "\tdrop_s = Dropout(0.05)(conv_s)\n",
    "\t#pool1 = MaxPooling1D(pool_size=1)(drop1)\n",
    "\tflat_s = Flatten()(drop_s)\n",
    "\t# features\n",
    "\tinput_features = Input(shape=(features_n, ))\n",
    "\tdens_f = Dense(100, activation='relu')(input_features)\n",
    "\tdrop_f = Dropout(0.05)(dens_f)\n",
    "\t#pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "\tflat_f = Flatten()(drop_f)\n",
    "\t    \n",
    "\t# merged sequences and features\n",
    "\tmerged = concatenate([flat_s, flat_f]) # merged sequences and features\n",
    "\n",
    "\tdense1 = Dense(200, activation='relu')(merged)\n",
    "\tdrop1 = Dropout(0.05)(dense1)\n",
    "\tdense2 = Dense(32, activation='relu')(drop1)\n",
    "\toutputs = Dense(8, activation='softmax')(dense2)\n",
    "\tmodel = Model(inputs=[input_seq, input_features], outputs=outputs)\n",
    "\t\n",
    "\tmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])\n",
    "\tprint(model.summary())\n",
    "\n",
    "\treturn model\n",
    "\n",
    "\n",
    "time_01 = time.time()\n",
    "print (\"\\nCNN classification by sequences and features\")\n",
    "\n",
    "#.fit([XF_train, S_train], y_train, epochs=70, batch_size=100)\n",
    "\n",
    "#score, acc = sequences_features.evaluate([XF_test, S_test], y_test, verbose=2)\n",
    "\n",
    "# define model\n",
    "model = define_model(8, 9, 6)\n",
    "\n",
    "# fit model\n",
    "model.fit([S_train, XF_train], y_train, epochs=100, batch_size=40)\n",
    "\n",
    "time_02 = time.time()\n",
    "\n",
    "# evaluate model on test dataset \n",
    "loss, acc = model.evaluate([S_test, XF_test], y_test, verbose=0)\n",
    "print('Test Accuracy: %f' % acc)\n",
    "\n",
    "time_03 = time.time()\n",
    "\n",
    "print (\"\\tModel fitting time .... %0.2f\" % (time_02 - time_01))\n",
    "print (\"\\tPrediction time ....... %0.2f\" % (time_03 - time_02))\n",
    "print (\"\\tTotal time ............ %0.2f\" % (time_03 - time_01))   \n",
    "print (\"Accuracy: %.3f\" % (acc))\n",
    "print (\"============================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
